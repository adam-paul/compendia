{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas config\n",
    "pd.options.display.max_rows = 1600\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "# Pyplot config\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHL season data\n",
    "start_year = 1917 # 1917 is the first year with data\n",
    "end_year = 2023\n",
    "all_years = range(start_year, end_year, 1)\n",
    "seasons = ['{}{}'.format(year, year+1) for year in all_years]\n",
    "    \n",
    "# Cup winners\n",
    "#cup_winners = pd.read_csv('cup-winners.csv', names=['year', 'team', 'abbr'])\n",
    "#cup_winners.loc[3] = ['2020', 'To Be Determined', 'TBD']\n",
    "#cup_winners.index = seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.urlopen('https://statsapi.web.nhl.com/api/v1/teams')\n",
    "req_json = req.read().decode()\n",
    "req_teams = dict(json.loads(req_json))['teams']\n",
    "req_names = [team['name'] for team in req_teams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHL Team Abbreviation Index\n",
    "\n",
    "req = urllib.request.urlopen('https://statsapi.web.nhl.com/api/v1/teams')\n",
    "req_json = req.read().decode()\n",
    "req_teams = dict(json.loads(req_json))['teams']\n",
    "req_names = [team['name'] for team in req_teams]\n",
    "\n",
    "teams_long = ['Anaheim Ducks',\n",
    "              'Arizona Coyotes',\n",
    "              'Atlanta Flames',\n",
    "              'Atlanta Thrashers',\n",
    "              'Boston Bruins',\n",
    "              'Brooklyn Americans',\n",
    "              'Buffalo Sabres',\n",
    "              'Calgary Flames',\n",
    "              'California Golden Seals',\n",
    "              'Carolina Hurricanes',\n",
    "              'Chicago Blackhawks',\n",
    "              'Cleveland Barons',\n",
    "              'Colorado Avalanche',\n",
    "              'Colorado Rockies',\n",
    "              'Columbus Blue Jackets',\n",
    "              'Dallas Stars',\n",
    "              'Detroit Cougars',\n",
    "              'Detroit Falcons',\n",
    "              'Detroit Red Wings',\n",
    "              'Edmonton Oilers',\n",
    "              'Florida Panthers',\n",
    "              'Hamilton Tigers',\n",
    "              'Hartford Whalers',\n",
    "              'Kansas City Scouts',\n",
    "              'Los Angeles Kings',\n",
    "              'Minnesota North Stars',\n",
    "              'Minnesota Wild',\n",
    "              'Montr√©al Canadiens',\n",
    "              'Montreal Maroons',\n",
    "              'Montreal Wanderers',\n",
    "              'Nashville Predators',\n",
    "              'New Jersey Devils',\n",
    "              'New York Americans',\n",
    "              'New York Islanders',\n",
    "              'New York Rangers',\n",
    "              'Oakland Seals',\n",
    "              'Ottawa Senators',\n",
    "              'Phoenix Coyotes',\n",
    "              'Philadelphia Flyers',\n",
    "              'Pittsburgh Penguins',\n",
    "              'Pittsburgh Pirates',\n",
    "              'Quebec Bulldogs',\n",
    "              'Philadelphia Quakers',\n",
    "              'Quebec Nordiques',\n",
    "              'San Jose Sharks',\n",
    "              'Seattle Kraken',\n",
    "              'Ottawa Senators (1917)',\n",
    "              'St. Louis Blues',\n",
    "              'St. Louis Eagles',\n",
    "              'Tampa Bay Lightning',\n",
    "              'Toronto Arenas',\n",
    "              'Toronto Maple Leafs',\n",
    "              'Toronto St. Patricks',\n",
    "              'Vancouver Canucks',\n",
    "              'Vegas Golden Knights',\n",
    "              'Washington Capitals',\n",
    "              'Winnipeg Jets',\n",
    "              'Winnipeg Jets (1979)']\n",
    "\n",
    "teams_short = ['ANA',\n",
    "               'ARI',\n",
    "               'AFM',\n",
    "               'ATL',\n",
    "               'BOS',\n",
    "               'BRK',\n",
    "               'BUF',\n",
    "               'CGY',\n",
    "               'CGS',\n",
    "               'CAR',\n",
    "               'CHI',\n",
    "               'CLE',\n",
    "               'COL',\n",
    "               'CLR',\n",
    "               'CBJ',\n",
    "               'DAL',\n",
    "               'DCG',\n",
    "               'DFL',\n",
    "               'DET',\n",
    "               'EDM',\n",
    "               'FLA',\n",
    "               'HAM',\n",
    "               'HFD',\n",
    "               'KCS',\n",
    "               'LAK',\n",
    "               'MNS',\n",
    "               'MIN',\n",
    "               'MTL',\n",
    "               'MMR',\n",
    "               'MWN',\n",
    "               'NSH',\n",
    "               'NJD',\n",
    "               'NYA',\n",
    "               'NYI',\n",
    "               'NYR',\n",
    "               'OAK',\n",
    "               'OTT',\n",
    "               'PHX',\n",
    "               'PHI',\n",
    "               'PIT',\n",
    "               'PIR',\n",
    "               'QBD',\n",
    "               'QUA',\n",
    "               'QUE',\n",
    "               'SJS',\n",
    "               'SEA',\n",
    "               'SEN',\n",
    "               'STL',\n",
    "               'SLE',\n",
    "               'TBL',\n",
    "               'TAN',\n",
    "               'TOR',\n",
    "               'TSP',\n",
    "               'VAN',\n",
    "               'VGK',\n",
    "               'WSH',\n",
    "               'WPG', \n",
    "               'WIN']\n",
    "\n",
    "team_index = dict(zip(teams_long, teams_short))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean build for current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS IS A CLEAN BUILD FOR THE CURRENT SEASON, JUST A TEMPLATE ###\n",
    "\n",
    "# First get the team data into a dataframe\n",
    "teams_req = urllib.request.urlopen('https://statsapi.web.nhl.com/api/v1/teams?expand=team.stats')\n",
    "teams_json = teams_req.read().decode()\n",
    "teams_meta = dict(json.loads(teams_json))\n",
    "teams_dict = {key['abbreviation']:key for key in teams_meta['teams']}\n",
    "teams_df = pd.DataFrame.from_dict(teams_dict)\n",
    "\n",
    "stats_dict = {team:teams_df[team]['teamStats'][0]['splits'][0]['stat'] for team in teams_df.columns}\n",
    "stats_df = pd.DataFrame.from_dict(stats_dict, orient='index')\n",
    "\n",
    "# Next we can get player rosters\n",
    "players_req = urllib.request.urlopen('https://statsapi.web.nhl.com/api/v1/teams?expand=team.roster')\n",
    "players_json = players_req.read().decode()\n",
    "players_meta = dict(json.loads(players_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling and building for all seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull team data for all seasons from NHL API\n",
    "teams_reqs = [urllib.request.urlopen( \\\n",
    "              'https://statsapi.web.nhl.com/api/v1/teams?expand=team.stats&season={}'.format( \\\n",
    "              season)) for season in seasons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode into readable JSON-like format\n",
    "teams_jsons = [req.read().decode() for req in teams_reqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in as JSON and collect appropriate segments into dictionary\n",
    "teams_metas = [dict(json.loads(fread))['teams'] for fread in teams_jsons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all team data for each season\n",
    "teams_dicts = [{key['abbreviation']:key for key in season} for season in teams_metas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dictionary for all teams for each season\n",
    "season_dict = dict(zip(seasons, teams_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stats dictionary\n",
    "stats_dict = {}\n",
    "\n",
    "for key in season_dict:\n",
    "    # Some seasons have no stats available, NaN results in KeyError\n",
    "    try:\n",
    "        stats_dict[key] = {season_dict[key][team]['abbreviation'] : \\\n",
    "                       season_dict[key][team]['teamStats'][0]['splits'][0]['stat'] \\\n",
    "                       for team in season_dict[key]}\n",
    "    except KeyError:\n",
    "    # Populate teams one at a time in years where some teams have no stats\n",
    "        stats_dict[key] = {}\n",
    "        for team in season_dict[key]:\n",
    "            try:\n",
    "                stats_dict[key][team] = season_dict[key][team]['teamStats'][0]['splits'][0]['stat']\n",
    "            except KeyError:\n",
    "                # Empty dictionary for teams with no stats (rather than NaN)\n",
    "                stats_dict[key][team] = {key:0 for key in season_dict['20002001']['COL']['teamStats'][0]['splits'][0]['stat']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dictionary of seasonal stats dataframes for each season\n",
    "stats_dfs = {key:pd.DataFrame.from_dict(stats_dict[key], orient='index') for key in stats_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_dict = {}\n",
    "\n",
    "for team in teams_short:\n",
    "    inner_season_dict = {}\n",
    "    \n",
    "    for season in season_dict.keys():\n",
    "        try:\n",
    "            inner_season_dict[season] = stats_dict[season][team]\n",
    "        except:\n",
    "            inner_season_dict[season] = {}\n",
    "\n",
    "    team_data_dict[team] = inner_season_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_dfs = {key:pd.DataFrame.from_dict(team_data_dict[key], orient='index') for key in team_data_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send = pd.Series(team_data_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in to_send.items():\n",
    "    df['season'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(to_send.values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Replace the following with your Azure PostgreSQL connection details\n",
    "database_username = \"adampaul\"\n",
    "database_password = \"pass\"\n",
    "database_host = \"compendia.postgres.database.azure.com\"\n",
    "database_port = \"5432\"\n",
    "database_name = \"compendia_db\"\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = f\"postgresql://{database_username}:{database_password}@{database_host}:{database_port}/{database_name}\"\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Write the combined DataFrame to the database\n",
    "table_name = \"team_data\"\n",
    "combined_df.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Add the composite primary key\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(f\"ALTER TABLE {table_name} ADD PRIMARY KEY (team_id, season);\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a new boolean array column to each seasonal dataframe to indicate Stanley Cup winner\n",
    "#for key in stats_dfs:\n",
    "#    win_bool = stats_dfs[key].index == cup_winners.loc[key]['abbr']\n",
    "#    stats_dfs[key]['cupWin'] = win_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player data (via ID lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the roster data? \n",
    "player_reqs = [urllib.request.urlopen( \\\n",
    "              'https://statsapi.web.nhl.com/api/v1/teams?expand=team.roster&season={}'.format( \\\n",
    "              season)) for season in seasons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode into readable JSON-like format\n",
    "player_jsons = [req.read().decode() for req in player_reqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in as JSON and collect appropriate segments into dictionary\n",
    "player_metas = [dict(json.loads(fread))['teams'] for fread in player_jsons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that connects each season to each team that played that season, and connect each of those teams to their corresponding roster data\n",
    "rosters = []\n",
    "\n",
    "for season in player_metas:\n",
    "    try:\n",
    "        rosters.append({team['abbreviation']:team['roster']['roster'] for team in season})\n",
    "        \n",
    "    except KeyError:\n",
    "        team_dict = {}\n",
    "        for team in season:\n",
    "            try:\n",
    "                team_dict[team['abbreviation']] = team['roster']['roster']\n",
    "            except KeyError:\n",
    "                team_dict[team['abbreviation']] = {}\n",
    "        rosters.append(team_dict)\n",
    "\n",
    "season_dicts = dict(zip(seasons, rosters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all of the player IDs and their full names\n",
    "all_ids = [season_dicts[season][team][x]['person']['id'] for season in seasons for team in season_dicts[season].keys() for x in range(len(season_dicts[season][team]))]\n",
    "all_names = [season_dicts[season][team][x]['person']['fullName'] for season in seasons for team in season_dicts[season].keys() for x in range(len(season_dicts[season][team]))]\n",
    "\n",
    "# Then combine them into a dictionary\n",
    "id_dict = dict(zip(all_names, all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns a player's year-by-year statistics\n",
    "\n",
    "def get_player_df(player):\n",
    "    # Make API request and parse into python data structure\n",
    "    stat_req = urllib.request.urlopen('https://statsapi.web.nhl.com/api/v1/people/{}/stats?stats=yearByYear'.format(id_dict[player]))\n",
    "    stat_json = stat_req.read().decode()\n",
    "    player_stat = dict(json.loads(stat_json))['stats'][0]['splits']\n",
    "    \n",
    "    # Convert to pandas dataframe with team column\n",
    "    player_stats = [player_season['stat'] for player_season in player_stat if player_season['league']['name'] == 'National Hockey League']\n",
    "    player_seasons = [player_season['season'] for player_season in player_stat if player_season['league']['name'] == 'National Hockey League']\n",
    "    player_teams = [player_season['team']['name'] for player_season in player_stat if player_season['league']['name'] == 'National Hockey League']\n",
    "    teams_abb = [team_index[team] for team in player_teams]\n",
    "    player_df = pd.DataFrame(player_stats, index=player_seasons)\n",
    "    player_df.insert(loc=0, column='team', value=teams_abb)\n",
    "    \n",
    "    return player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = get_player_df('Jaromir Jagr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_dfs = {player:get_player_df(player) for player in id_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_db = pd.Series(player_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in to_db.items():\n",
    "    df['player_name'] = key\n",
    "    df['season'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_player_df = pd.concat(to_db.values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name):\n",
    "    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n",
    "\n",
    "# Rename columns\n",
    "combined_player_df.columns = [camel_to_snake(col) for col in combined_player_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace = ['penalty_minutes', 'time_on_ice', 'power_play_time_on_ice', 'even_time_on_ice', 'short_handed_time_on_ice']\n",
    "\n",
    "for col in columns_to_replace:\n",
    "    combined_player_df.loc[combined_player_df[col].isna(), col] = pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with duplicated values in columns 'A', 'B', and 'C'\n",
    "duplicated_rows = combined_player_df.duplicated(subset=['season', 'player_name', 'team'], keep=False)\n",
    "\n",
    "# Display the duplicated rows\n",
    "doubles = combined_player_df[duplicated_rows]['player_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_traded = ['George Carroll',\n",
    "                 'Roy Worters',\n",
    "                 'Ron Lyons',\n",
    "                 'Claude Bourque',\n",
    "                 'Paul Masnick',\n",
    "                 'Larry Brown',\n",
    "                 'Gary Mcadam',\n",
    "                 'Vaclav Nedomansky',\n",
    "                 'Dean Kennedy',\n",
    "                 'Jarrod Skalde',\n",
    "                 'Harold Druken',\n",
    "                 'Craig Anderson',\n",
    "                 'Joel Perrault',\n",
    "                 'David Koci',\n",
    "                 'Ben Maxwell',\n",
    "                 'Derek Grant',\n",
    "                 'Chris Wagner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef convert_to_time(x):\\n    try:\\n        return datetime.strptime(x, \"%M:%S\").time()\\n    except:\\n        return x\\n\\nfor col in columns_to_replace:\\n    filtered_df[col] = filtered_df[col].apply(convert_to_time)\\n'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def custom_time_parser(time_str):\n",
    "    if ':' not in time_str:\n",
    "        return None\n",
    "    parts = time_str.split(':')\n",
    "    if len(parts) == 3:\n",
    "        hours, minutes, seconds = [int(p) for p in parts]\n",
    "    elif len(parts) == 2:\n",
    "        hours = 0\n",
    "        minutes, seconds = [int(p) for p in parts]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "    return timedelta(seconds=total_seconds)\n",
    "\n",
    "def sum_time_objects(series):\n",
    "    time_objects = [custom_time_parser(t) if not pd.isna(t) else t for t in series]\n",
    "    total_seconds = sum([t.total_seconds() for t in time_objects if not pd.isna(t)])\n",
    "    total_seconds = int(total_seconds)\n",
    "    minutes, seconds = divmod(total_seconds, 60)\n",
    "    return f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "def sum_pims(series):\n",
    "    total_minutes = sum(int(t) for t in series if not pd.isna(t))\n",
    "    return total_minutes\n",
    "\n",
    "aggregations = {\n",
    "    'team': 'first',\n",
    "    'player_name': 'first',\n",
    "    'season': 'first',\n",
    "    'assists': 'sum',\n",
    "    'goals': 'sum',\n",
    "    'pim': 'sum',\n",
    "    'games': 'sum',\n",
    "    'game_winning_goals': 'sum',\n",
    "    'over_time_goals': 'sum',\n",
    "    'points': 'sum',\n",
    "    'shutouts': 'sum',\n",
    "    'ties': 'sum',\n",
    "    'wins': 'sum',\n",
    "    'losses': 'sum',\n",
    "    'goal_against_average': 'sum',\n",
    "    'games_started': 'sum',\n",
    "    'goals_against': 'sum',\n",
    "    'power_play_goals': 'sum',\n",
    "    'power_play_points': 'sum',\n",
    "    'short_handed_goals': 'sum',\n",
    "    'short_handed_points': 'sum',\n",
    "    'shots': 'sum',\n",
    "    'hits': 'sum',\n",
    "    'face_off_pct': 'sum',\n",
    "    'shot_pct': 'sum',\n",
    "    'blocked': 'sum',\n",
    "    'plus_minus': 'sum',\n",
    "    'shifts': 'sum',\n",
    "    'saves': 'sum',\n",
    "    'power_play_saves': 'sum',\n",
    "    'short_handed_saves': 'sum',\n",
    "    'even_saves': 'sum',\n",
    "    'save_percentage': 'sum',\n",
    "    'shots_against': 'sum',\n",
    "    'short_handed_shots': 'sum',\n",
    "    'even_shots': 'sum',\n",
    "    'power_play_shots': 'sum',\n",
    "    'power_play_save_percentage': 'sum',\n",
    "    'short_handed_save_percentage': 'sum',\n",
    "    'even_strength_save_percentage': 'sum',\n",
    "    'ot': 'sum',\n",
    "\n",
    "    # Time columns\n",
    "    'penalty_minutes': lambda x: sum_pims(x),\n",
    "    'time_on_ice': lambda x: sum_time_objects(x),\n",
    "    'power_play_time_on_ice': lambda x: sum_time_objects(x),\n",
    "    'even_time_on_ice': lambda x: sum_time_objects(x),\n",
    "    'short_handed_time_on_ice': lambda x: sum_time_objects(x),\n",
    "}\n",
    "\n",
    "# Step 2: Filter the DataFrame\n",
    "filtered_df = combined_player_df[combined_player_df['player_name'].isin(double_traded)]\n",
    "\n",
    "columns_to_replace = ['penalty_minutes', 'time_on_ice', 'power_play_time_on_ice', 'even_time_on_ice', 'short_handed_time_on_ice']\n",
    "\n",
    "for col in columns_to_replace:\n",
    "    filtered_df.loc[filtered_df[col].isna(), col] = pd.NaT\n",
    "\n",
    "'''\n",
    "def convert_to_time(x):\n",
    "    try:\n",
    "        return datetime.strptime(x, \"%M:%S\").time()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "for col in columns_to_replace:\n",
    "    filtered_df[col] = filtered_df[col].apply(convert_to_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Group and aggregate\n",
    "grouped_df = filtered_df.groupby(['team', 'player_name', 'season']).agg(aggregations).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20700/2675136325.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_player_df = combined_player_df[~combined_player_df['player_name'].isin(double_traded)].append(grouped_df).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Merge the aggregated rows back to the original DataFrame\n",
    "combined_player_df = combined_player_df[~combined_player_df['player_name'].isin(double_traded)].append(grouped_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        George Boucher\n",
       "1        George Boucher\n",
       "2        George Boucher\n",
       "3        George Boucher\n",
       "4        George Boucher\n",
       "              ...      \n",
       "53494      Dean Kennedy\n",
       "53495      Dean Kennedy\n",
       "53496       Ben Maxwell\n",
       "53497    Craig Anderson\n",
       "53498       Gary Mcadam\n",
       "Name: player_name, Length: 53499, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_player_df['player_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_player_df = combined_player_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Replace the following with your Azure PostgreSQL connection details\n",
    "database_username = \"adampaul\"\n",
    "database_password = \"pass\"\n",
    "database_host = \"compendia.postgres.database.azure.com\"\n",
    "database_port = \"5432\"\n",
    "database_name = \"compendia_db\"\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = f\"postgresql://{database_username}:{database_password}@{database_host}:{database_port}/{database_name}\"\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Write the combined DataFrame to the database\n",
    "table_name = \"player_data\"\n",
    "final_player_df.to_sql(table_name, engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
